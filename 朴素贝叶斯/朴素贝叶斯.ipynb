{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最近在看《机器学习实战》，里面有一个朴素贝叶斯理论，这个理论并不难，不过书上说得挺绕，网上有个博客挺好，简单明了，可以看一下：[朴素贝叶斯分类器的应用](http://www.ruanyifeng.com/blog/2013/12/naive_bayes_classifier.html)。通过病人分类和账号分类的例子，应该就比较清楚朴素贝叶斯分类器是干啥的了，算出在哪个特征（Feature）的前提下，分类（Category）的概率最高，就划分到那个分类中就行了。我们使用书上狗狗论坛的例子，有如下几段文字，将其分类为侮辱性和非侮辱性，0代表正常言论，1代表侮辱言论："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loadDataSet():\n",
    "    postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "                 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                 ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    classVec = [0,1,0,1,0,1]    #1 is abusive, 0 not\n",
    "    return postingList,classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
      "[0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "listOPosts,listClasses = loadDataSet()\n",
    "print(listOPosts)\n",
    "print(listClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来就是统计有哪些单词，这些单词将会组成我们的特征（Feature）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createVocabList(dataSet):\n",
    "    vocabSet = set([])  #create empty set\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document) #union of the two sets\n",
    "    return list(vocabSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['help', 'maybe', 'how', 'steak', 'stupid', 'problems', 'I', 'dalmation', 'my', 'ate', 'mr', 'is', 'not', 'so', 'flea', 'park', 'cute', 'to', 'stop', 'worthless', 'posting', 'licks', 'dog', 'take', 'love', 'please', 'garbage', 'quit', 'buying', 'food', 'has', 'him']\n"
     ]
    }
   ],
   "source": [
    "myVocabList = createVocabList(listOPosts)\n",
    "print(myVocabList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在书中，使用了词向量这一概念，这样做的好处是一切向量化，好处理，不过也不太适合初学者理解，所以我的博客中想尝试不用词向量，这样看起来更直观。现在开始统计每个单词的在侮辱性和非侮辱性语句中出现的概率也就是统计$P(f_{i}|c=0)$和$P(f_{i}|c=1)$，这里的$f_{i}$指的是某个单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProb(postingList,classVec):\n",
    "    classSet=set(classVec)#统计有多少种类别\n",
    "    classProb=dict((x,classVec.count(x)/len(classVec)) for x in  classVec)\n",
    "    feature=[]\n",
    "    for c in classSet:\n",
    "        feature.append([y for x,i in zip(postingList,classVec) if i==c for y in x])\n",
    "    allCount=[len(x) for x in feature]\n",
    "    prob=[]\n",
    "    for w,c in zip(feature,allCount):\n",
    "        prob.append(dict((x, w.count(x)/c) for x in w))#统计侮辱性语句中每个单词出现的数目\n",
    "    return [prob,classProb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'I': 0.041666666666666664,\n",
       "   'ate': 0.041666666666666664,\n",
       "   'cute': 0.041666666666666664,\n",
       "   'dalmation': 0.041666666666666664,\n",
       "   'dog': 0.041666666666666664,\n",
       "   'flea': 0.041666666666666664,\n",
       "   'has': 0.041666666666666664,\n",
       "   'help': 0.041666666666666664,\n",
       "   'him': 0.08333333333333333,\n",
       "   'how': 0.041666666666666664,\n",
       "   'is': 0.041666666666666664,\n",
       "   'licks': 0.041666666666666664,\n",
       "   'love': 0.041666666666666664,\n",
       "   'mr': 0.041666666666666664,\n",
       "   'my': 0.125,\n",
       "   'please': 0.041666666666666664,\n",
       "   'problems': 0.041666666666666664,\n",
       "   'so': 0.041666666666666664,\n",
       "   'steak': 0.041666666666666664,\n",
       "   'stop': 0.041666666666666664,\n",
       "   'to': 0.041666666666666664},\n",
       "  {'buying': 0.05263157894736842,\n",
       "   'dog': 0.10526315789473684,\n",
       "   'food': 0.05263157894736842,\n",
       "   'garbage': 0.05263157894736842,\n",
       "   'him': 0.05263157894736842,\n",
       "   'maybe': 0.05263157894736842,\n",
       "   'not': 0.05263157894736842,\n",
       "   'park': 0.05263157894736842,\n",
       "   'posting': 0.05263157894736842,\n",
       "   'quit': 0.05263157894736842,\n",
       "   'stop': 0.05263157894736842,\n",
       "   'stupid': 0.15789473684210525,\n",
       "   'take': 0.05263157894736842,\n",
       "   'to': 0.05263157894736842,\n",
       "   'worthless': 0.10526315789473684}],\n",
       " {0: 0.5, 1: 0.5}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getProb(listOPosts,listClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样我们就知道了所有的单词在某一类别的概率了，为了让大家更直观，我们这里手动算1个：  \n",
    "$P(dog|c=0)$的计算：dog在正常语句中出现了1次，正常语句一共有24个（重复单词也重复计算），所以$P(dog|c=0)=\\frac{1}{24}=0.0417$  \n",
    "$P(dog|c=1)$的计算：dog在侮辱语句中出现了2次，正常语句一共有19个，所以$P(dog|c=0)=\\frac{2}{19}=0.1052$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
